---
title: "Assignment 4 - Applying meta-analytic priors"
author: "Riccardo Fusaroli"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

setwd("C:/Users/nanna/OneDrive - Aarhus universitet/4. Semester/Experimental Methods 4/Assignment 4")


```

## Assignment 4

In this assignment we do the following:
- we reproduce the meta-analysis of pitch SD from last semester in a Bayesian framework
- we reproduce the pitch SD in schizophrenia analysis from last semester using both a conservative and a meta-analytic prior
- we assess the difference in model quality and estimates using the two priors.

The questions you need to answer are: 

What are the consequences of using a meta-analytic prior? 
  Evaluate the models with conservative and meta-analytic priors. 
  Discuss the effects on estimates. Discuss the effects on model quality.
  Discuss the role that meta-analytic priors should have in scientific practice. 
  
  Should we systematically use them? 
  
  Do they have drawbacks? 
  
  Should we use them to complement more conservative approaches? 
  
  How does the use of meta-analytic priors you suggest reflect the skeptical and cumulative nature of science?

## Step by step suggestions


##Step 1: Reproduce the meta-analysis of pitch sd from previous studies of voice in schizophrenia
- the data is available as Assignment4MetaData.xlsx

- Effect size (cohen's d), sd and variance are already calculated (you're welcome!)

- Since we're only interested in getting a meta-analytic effect size, let's take a shortcut and use bromance magic (brms): https://vuorre.netlify.com/post/2016/09/29/meta-analysis-is-a-special-case-of-bayesian-multilevel-modeling/

```{r + libraries}
library(pacman)

library(devtools)
devtools::install_github("rmcelreath/rethinking", force = T)
library(rethinking)
library(brms)
library(tidyverse)
p_load(metafor, lme4, rethinking, brms, tidyverse)
p_load(brms, gridExtra)
p_load("readxl")

```

```{r + data}

# xls files
meta <- read_excel("Assignment4MetaData.xlsx")
# xlsx files
pitch <- read_excel("Assignment4PitchDatav2.xlsx")

```

```{r}

library(ggplot2)
ggplot(meta, aes(x=MeanES, y=StudyRef)) +
  geom_segment(aes(x = MeanES-SdES*2, xend = MeanES+SdES*2, y=StudyRef, yend=StudyRef)) +
  geom_point()

```


```{r + State of the art}

#state of the art 
#Get popoulation priors

meta_mod <- brm(
  MeanES | se(VarianceES) ~ 1 + (1 | StudyID), 
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "sd")),
  iter = 10000,
  data = meta, 
  cores = 4
)


meta_mod

plot(meta_mod)

pairs(meta_mod)


#devtools::install_github("mvuorre/brmstools")
#library(brmstools)
#brmstools::forest(meta_mod,
       #show_data = TRUE,
       #av_name = "Effect size")



```

##Step 2: Prepare the pitch SD data from last year
- the data is available as Assignment4PitchData.csv (thanks Celine)
- Also, let's standardize the data, so that they are compatible with our meta-analytic prior (Cohen's d is measured in SDs).

```{r + standardize the data}

pitch$pitchmean_s = scale(pitch$PitchMean)
pitch$pitchSD_s = scale(pitch$PitchSD)
pitch$pitchmedian_s = scale(pitch$PitchMedian)
pitch$pitchrange_s = scale(pitch$PitchRange)
pitch$pitchIQR_s = scale(pitch$PitchIQR)
pitch$pitchmad_s = scale(pitch$PitchMad)


#Make a dateframe with the standardized data
pitch_s <- 
  dplyr::select(pitch, ID_unique, diagnosis, studynr, trial, 13:18, PitchCV)

```

- Is there any structure in the dataset that we should account for with random effects? 

Yes. Study. 

How would you implement that? Or, if you don't know how to do bayesian random effects, is there anything we would need to simplify in the dataset?

##Step 3: Build a regression model predicting Pitch SD from Diagnosis.
- how is the outcome distributed? (likelihood function)
- how are the parameters of the likelihood distribution distributed? Which predictors should they be conditioned on?
- use a skeptical/conservative prior for the effects of diagnosis. Remember you'll need to motivate it.
- Describe and plot the estimates. Evaluate model quality

```{r + Conservative priors (NOT USED AT ALL)}

brm_mod <- brm(
 pitchSD_s ~ 1 + diagnosis + (1 | studynr), 
  prior = c(
    prior(normal(0, 0.1), class = "Intercept"),
    prior(cauchy(0, 0.5), class = "sd"),
    prior(normal(0, 0.1), class = "b"),
    prior(cauchy(0, 1), class = "sigma")),
  data = pitch_s, 
  cores = 4
)


brm_mod
plot(brm_mod)



#Checking the model 

pp_check(brm_mod)

pp_check(brm_mod, nsamples = 100,
         type = "intervals_grouped", group = 'studynr')


#How did the sampling go?
pairs(brm_mod, np = nuts_params(brm_mod))


#Unlike the way rethinking’s extract.samples() yields a list, brms’s posterior_samples() returns a data frame.
  
post <- posterior_samples(brm_mod)

str(post)
pairs(post)

pairs(brm_mod,
      off_diag_args = list(size = 1/5, alpha = 1/5))


#Another nice way to customize your pairs plot is with the GGally package.
p_load(GGally)

post %>%
  select(b_Intercept:sigma) %>%
  ggpairs()


waic(brm_mod)


```

```{r + Conservative model with more parameters}
#Chaning diagnosis to a fator 
pitch_s$diagnosis <- as.factor(pitch_s$diagnosis)


#Finding variables to set priors for
cons.model <- bf(pitchSD_s ~ 1 + diagnosis + (1 | ID_unique) + (1 | trial / studynr))
get_prior(cons.model, pitch_s)


#Making the model
brm_mod_all <- brm(
 pitchSD_s ~ 1 + diagnosis + (1 | ID_unique) + (1 | trial / studynr), 
  prior = c(
    prior(normal(0, 0.1), class = "Intercept"),
    prior(cauchy(0, 0.1), class = "sd", coef = "Intercept", group = ID_unique),
    prior(cauchy(0, 0.1), class = "sd", coef = "Intercept", group = trial:studynr),
    prior(normal(0, 0.2), class = "b"),
    prior(cauchy(0, 1), class = "sigma")),
  data = pitch_s,
 iter = 10000,
  cores = 4
)

#Looking at the output
summary(brm_mod_all)

#Checking the model
plot(brm_mod_all, pars = "^b_")
pp_check(brm_mod_all)


#How did the sampling go?
pairs(brm_mod_all, np = nuts_params(brm_mod_all))

#Another nice way to customize your pairs plot is with the GGally package.
p_load(GGally)

post %>%
  select(b_Intercept:sigma) %>%
  ggpairs()



#Looking at plot for marginal effects
brms::marginal_effects(brm_mod_all)
##Almost complete overlap

```


```{r + Checking the chain}

p_load(bayesplot)

post1 <- posterior_samples(brm_mod_all, add_chain = T)

mcmc_trace(post1[, c(1:5,197)],  # we need to include column 7 because it contains the chain info 
           facet_args = list(ncol = 2), 
           size = .15) +
  labs(title = "Our custom trace plots #caterpillar") + scale_color_discrete() + theme_light()

```



```{r + inspecting the estimates}

p25 <- 
  ggplot(data =  pitch_s, 
         aes(x = diagnosis, y = pitchSD_s)) +
  geom_abline(intercept = post1[1:25, 1], 
              slope     = post1[1:25, 2],
              size = 1/3, alpha = .3) +
  
  geom_point(shape = 1, size = 2, color = "royalblue") +
  coord_cartesian(ylim = range(pitch_s$pitchSD_s)) +
  labs(subtitle = "How the models captures the data. Conservative model. N = 25") +
  theme_bw() +
  theme(panel.grid = element_blank())

p25

```




```{r + making predictions using fitted - NOT USED}

pitchSD_seq <- tibble(PitchSD_s = seq(from = -3, to = 3, length.out = 1178))

# now use `fitted()` to get the model-implied trajectories
f <- 
  fitted(brm_mod_all,
         new_data = pitchSD_seq) %>%
  as_tibble() %>%
  # tack the `pitch_s` data onto the `fitted()` results
  bind_cols(pitchSD_seq)

 #fitted(brm_mod_all)

pitch_s %>%
  ggplot(aes(x = pitch_s$pitchSD_s, y = diagnosis))+
  geom_smooth(data = f,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              fill = "grey70", color = "black", alpha = 1, size = 1/2) +
  #geom_point(color = "navyblue", shape = 1, size = 1.5, alpha = 2/3) +
  #coord_cartesian(xlim = range(pitch_s$pitchSD_s)) +
        panel.grid = element_blank()


f %>%
  ggplot(aes(x = diagnosis, y = pitchSD_seq)) +
  geom_abline(intercept = fixef(brm_mod_all)[1], 
              slope     = fixef(brm_mod_all)[2]) +
  geom_point(shape = 1, size = 2, color = "royalblue") +
  theme_bw() +
  theme(panel.grid = element_blank())


# plot
p_load(Hmisc )

plot1 <- f %>% 
  ggplot(aes(x = diagnosis, y = Estimate,
             color = factor(diagnosis),
             fill = factor(diagnosis))) + 
  geom_violin() +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult = 1), geom = "pointrange", color = "black") +
  scale_x_continuous(limits=c(-1,3)) + 
  #geom_jitter(alpha = 0.4, width = 0.4) 
  coord_flip()


plot2 <- f %>% 
  ggplot(aes(x = as.factor(diagnosis), y = pitchSD_s,
             color = factor(diagnosis),
             fill = factor(diagnosis))) + 
  geom_violin() + 
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult = 1), geom = "pointrange", color = "black") +
  #geom_jitter(alpha = 0.4, width = 0.4)
  coord_flip(xlim = c(-1, 4))

grid.arrange(plot1,plot2)


```

```{r + plotting prediction as density + NOT USED}

pred.plot1 <- f %>%
  filter(diagnosis == 1) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = 0, sd = 0.1), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) + geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + 
  
  labs(title = "Estimated data versus actual data (Diagnosis 1)",
       y     = "density") + theme(legend.position = "none")


pred.plot2 <- f %>%
  filter(diagnosis == 0) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = 0, sd = 0.1), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + 
  labs(title = "Estimated data versus actual data (Diagnosis 0)",
       y     = "density")+ theme(legend.position = "none")

grid.arrange(pred.plot1, pred.plot2)

```

##Step 4: Now re-run the model with the meta-analytic prior

- Describe and plot the estimates. Evaluate model quality

``` {r + metamodel}

#Making the model with meta priors on diagnosis
meta_prior <- brm(
 pitchSD_s ~ 1 + diagnosis + (1 | ID_unique) + (1 | trial/studynr), 
  prior = c(
    prior(normal(0, 0.1), class = "Intercept"),
    prior(cauchy(0, 0.1), class = "sd", coef = "Intercept", group = ID_unique),
    prior(cauchy(0, 0.1), class = "sd", coef = "Intercept", group = trial:studynr),
    prior(normal(-0.61, 0.29), class = "b"),
    prior(cauchy(0, 1), class = "sigma")),
 iter = 10000, 
  data = pitch_s, 
  cores = 4
)

#Estimates
summary(meta_prior)

#Checking the model
pp_check(meta_prior)
#plot(meta_prior)

#How did the sampling go?
pairs(meta_prior, np = nuts_params(meta_prior))

#Looking at the marginal effects 
brms::marginal_effects(meta_prior)

```

```{r + meta traceplots}

meta.post <- posterior_samples(meta_prior, add_chain = T)

mcmc_trace(meta.post[, c(1:5,197)],  # we need to include column 7 because it contains the chain info 
           facet_args = list(ncol = 2), 
           size = .15) +
  labs(title = "Our custom trace plots #caterpillar") + scale_color_discrete() + theme_light()

```

```{r + post plot}

post.m <- posterior_samples(meta_prior, add_chain = T)

p25meta <- 
  ggplot(data =  pitch_s, 
         aes(x = diagnosis, y = pitchSD_s)) +
  geom_abline(intercept = post.m[1:25, 1], 
              slope     = post.m[1:25, 2],
              size = 1/3, alpha = .3) +
  
  geom_point(shape = 1, size = 2, color = "royalblue") +
  coord_cartesian(ylim = range(pitch_s$pitchSD_s)) +
  labs(subtitle = "How the models captures the data. Meta Model. N = 25") +
  theme_bw() +
  theme(panel.grid = element_blank())

p25meta


```




```{r + prediciton using fitted NOT USED AT ALL}

# now use `fitted()` to get the model-implied trajectories
 mm <-  fitted(meta_prior) %>%
  as_tibble() %>%
  # tack the `pitch_s` data onto the `fitted()` results
  bind_cols(pitch_s)
```

```{r + plotting meta model density NOT USED }


pred.plot.mm1 <- mm %>%
  filter(diagnosis == 1) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = -0.61, sd = 0.28), linetype = 2) + 
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
  scale_x_continuous(limits=c(-3,3)) + 
  
  labs(title = "Estimated data versus actual data for meta prior model (Diagnosis 1)",
       y     = "density") + theme(legend.position = "none")


pred.plot.mm2 <- mm %>%
  filter(diagnosis == 0) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = -0.61, sd = 0.28), linetype = 2) + 
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
  scale_x_continuous(limits=c(-3,3)) + 
  labs(title = "Estimated data versus actual data for meta prior model (Diagnosis 0)",
       y     = "density")+ theme(legend.position = "none")

grid.arrange(pred.plot.mm1, pred.plot.mm2)

```


##Step 5: Compare the models
- Plot priors and posteriors of the diagnosis effect in both models
- Compare posteriors between the two models
- Compare their relative distance from truth (WAIC)
- Discuss how they compare and whether any of them is best.

```{r + plotting the models against each other pp checks}
p_load(cowplot)

p1 <- pp_check(brm_mod_all) +
  facet_wrap(~pitch$diagnosis)+
   ggtitle("PPC for conservative model")

p1

p2 <- pp_check(meta_prior) +
  facet_wrap(~pitch$diagnosis)+
  ggtitle("PPC for metaanalytic priors")

p2

plot_grid(p1, p2)

```

```{r + NOT USED COMPARISON}
plot.brm.all <- f %>%
  ggplot(aes(x = Estimate)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 0.2), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) + geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + scale_y_continuous(limits=c(-0,2)) +
  
  labs(title = "Estimated data versus actual data for model (m =0, SD = 0.2)",
       y     = "density") + theme(legend.position = "none")


plot.meta.prior <- mm %>%
    ggplot(aes(x = Estimate)) +
  stat_function(fun = dnorm, args = list(mean = -0.61, sd = 0.29), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + scale_y_continuous(limits=c(-0,2)) +
  labs(title = "Estimated data versus actual data for meta model (m =-0.61, SD = 0.29)",
       y     = "density")+ theme(legend.position = "none")

grid.arrange(plot.brm.all, plot.meta.prior)
```


```{r + WAIC comparison }

# compute and save the WAIC information for the next three models
brm_mod_all <- add_criterion(brm_mod_all, "waic")
meta_prior <- add_criterion(meta_prior, "waic")


# compare the WAIC estimates
w <- loo_compare(brm_mod_all, meta_prior,
                 criterion = "waic")

print(w, simplify = F)


#Calculating weights
model_weights(brm_mod_all, meta_prior, 
              weights = "waic") %>% 
  round(digits = 2)


```


##Step 6: Prepare a nice write up of the analysis and answer the questions at the top.

YES!




##Optional 

Optional step 7: how skeptical should a prior be?
- Try different levels of skepticism and compare them using WAIC.

We tried being very, very skeptical. As if our model was supposed to convince someone who did not believe in this effect at all. 


Optional step 8: Include other predictors
- Do age, gender and education improve the model?
- Should they be main effects or interactions?

Optional step 9: Bromance magic.
- explore the bromance code below including random effects (by default with weakly informative priors)
- learn how to change the prior
- explore effects of trial, age, gender, including the appropriate random slopes
- compare the models you created using WAIC and posterior predictive check (pp_check())


```{r}

brm_out <- brm(PitchSD ~ 1 + Diagnosis  +(1|ID_unique/Study), # Outcome as a function of the predictors as in lme4. 
               data=Data, # Define the data
               family=gaussian(), # Define the family. 
               iter = 5000, warmup = 2000, cores = 4)
summary(brm_out1)
plot(brm_out1)

```

